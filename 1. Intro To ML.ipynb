{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.498452Z",
     "start_time": "2023-06-04T09:20:35.473242Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.505379Z",
     "start_time": "2023-06-04T09:20:37.500448Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating 20k random values between 1 to 20 for 2 columns\n",
    "x1=np.random.randint(low=1,high=20,size=20000)\n",
    "\n",
    "\n",
    "x2=np.random.randint(low=1,high=20,size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.524863Z",
     "start_time": "2023-06-04T09:20:37.509372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 14,  2, ..., 17,  9, 14])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.534891Z",
     "start_time": "2023-06-04T09:20:37.528367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  5, 12, ...,  4,  9, 12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.543463Z",
     "start_time": "2023-06-04T09:20:37.537136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-666.38734849,  -56.08451761, -456.40778519, ...,   13.28598947,\n",
       "       -266.85281226, -336.774109  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equation for Y (Y estimation)\n",
    "\n",
    "#B0=3\n",
    "#B1=2\n",
    "#B2=-4\n",
    "\n",
    "y=3 + 10*x1 - 40*x2 + np.random.random(20000) # adding random errors to each instance\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see that we have generated data such that y is an approximate linear combination of x1 and x2, next we'll calculate optimal parameter values using gradient descent and compare them with results from sklearn and we'll see how good is the method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.551443Z",
     "start_time": "2023-06-04T09:20:37.545460Z"
    }
   },
   "outputs": [],
   "source": [
    "x=pd.DataFrame({'intercept':np.ones(x1.shape[0]),'x1':x1,'x2':x2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.558751Z",
     "start_time": "2023-06-04T09:20:37.553438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.575184Z",
     "start_time": "2023-06-04T09:20:37.562738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intercept  x1  x2\n",
       "0        1.0   5  18\n",
       "1        1.0  14   5\n",
       "2        1.0   2  12\n",
       "3        1.0  10  16\n",
       "4        1.0   2   6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.582168Z",
     "start_time": "2023-06-04T09:20:37.578187Z"
    }
   },
   "outputs": [],
   "source": [
    "w=np.random.random(x.shape[1]) # weights or coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.592081Z",
     "start_time": "2023-06-04T09:20:37.585705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87117247, 0.81970427, 0.05739824])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.599612Z",
     "start_time": "2023-06-04T09:20:37.594621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-666.38734849,  -56.08451761, -456.40778519, ...,   13.28598947,\n",
       "       -266.85281226, -336.774109  ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets write functions for predictions, error, cost and gradient that we discussed above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.611848Z",
     "start_time": "2023-06-04T09:20:37.602864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intercept  x1  x2\n",
       "0        1.0   5  18\n",
       "1        1.0  14   5\n",
       "2        1.0   2  12\n",
       "3        1.0  10  16\n",
       "4        1.0   2   6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.618374Z",
     "start_time": "2023-06-04T09:20:37.614382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87117247, 0.81970427, 0.05739824])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.632594Z",
     "start_time": "2023-06-04T09:20:37.620369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.00286204, 12.6340234 ,  3.19935983, ..., 15.03573797,\n",
       "        8.765095  , 13.03581104])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def myprediction(features,weights):\n",
    "\n",
    "    predictions=np.dot(features,weights)\n",
    "    return(predictions)\n",
    "\n",
    "myprediction(x,w)\n",
    "\n",
    "# function numpy.dot : is used for matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that , `np.dot` here is being used for matrix multiplication . Simple multiplication results to element wise multiplication , which is simply wrong in this context ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.653573Z",
     "start_time": "2023-06-04T09:20:37.635591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-672.39021053,  -68.71854101, -459.60714501, ...,   -1.7497485 ,\n",
       "       -275.61790726, -349.80992005])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def myerror(target,features,weights):\n",
    "    error=target-myprediction(features,weights)\n",
    "    return(error)\n",
    "myerror(y,x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.665587Z",
     "start_time": "2023-06-04T09:20:37.655602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2852554090.640471"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mycost(target,features,weights):\n",
    "    error=myerror(target,features,weights)\n",
    "    cost=np.dot(error.T,error)\n",
    "    return(cost)\n",
    "\n",
    "mycost(y,x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.672568Z",
     "start_time": "2023-06-04T09:20:37.666585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:37.687638Z",
     "start_time": "2023-06-04T09:20:37.675643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 304.26806958, 2768.98815694, 4215.13653476])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient(target,features,weights):\n",
    "    \n",
    "    error=myerror(target,features,weights)\n",
    "    \n",
    "    gradient=-np.dot(features.T,error)/features.shape[0]\n",
    "    \n",
    "    return(gradient)\n",
    "\n",
    "gradient(y,x,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that gradient here is vector of 3 values because there are 3 parameters . Also since this is being evaluated on the entire data, we scaled it down with number of observations . Do recall that , the approximation which led to the ultimate results was that change in parameters is small. We dont have any direct control over gradient , we can always chose a small value for $\\eta$ to ensure that change in parameter remains small. Also if we end up chosing too small value for $\\eta$, we'll need to take larger number of steps to change in parameter in order to arrive at the optimal value of the parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets looks at the expected value for parameters from sklearn . Dont worry about the syntax here , we'll discuss that in detail, when we formally start with linear models in next module ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:38.507064Z",
     "start_time": "2023-06-04T09:20:37.690664Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:38.539537Z",
     "start_time": "2023-06-04T09:20:38.508063Z"
    }
   },
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(x.iloc[:,1:],y)\n",
    "sk_estimates=([lr.intercept_]+list(lr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:38.548028Z",
     "start_time": "2023-06-04T09:20:38.541533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5101277623905958, 9.999609579613075, -40.00052619962942]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the same , these might be different for you, as we generated the data randomly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets write our version of this , using gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:38.558552Z",
     "start_time": "2023-06-04T09:20:38.551021Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_lr(target,features,learning_rate,num_steps,print_when):\n",
    "    \n",
    "    # start with random values of parameters\n",
    "    weights=np.random.random(features.shape[1])\n",
    "    \n",
    "    # change parameter multiple times in sequence \n",
    "    # using the cost function gradient which we discussed earlier \n",
    "    for i in range(num_steps):\n",
    "        \n",
    "        weights =weights- learning_rate*gradient(target,features,weights)\n",
    "       \n",
    "    # this simply prints the cost function value every (print_when)th iteration\n",
    "        if i%print_when==0:\n",
    "            print(\"Output at run\", i, \" - \", mycost(target,features,weights),weights)\n",
    "        \n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:39.250985Z",
     "start_time": "2023-06-04T09:20:38.565538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at run 0  -  2696310399.056165 [ 0.03096432 -0.16976182 -0.18284896]\n",
      "Output at run 10  -  1928543697.8459496 [-0.23178585 -2.46003703 -3.92592273]\n",
      "Output at run 20  -  1432958617.8395758 [-0.4399563  -4.14295558 -7.02377236]\n",
      "Output at run 30  -  1108984544.3704846 [-0.60488507 -5.3486192  -9.60656556]\n",
      "Output at run 40  -  893461089.2868282 [ -0.73555408  -6.17997772 -11.77753502]\n",
      "Output at run 50  -  746707597.3014926 [ -0.83907884  -6.71847496 -13.61857247]\n",
      "Output at run 60  -  643780822.1166035 [ -0.92109622  -7.02852139 -15.19466035]\n",
      "Output at run 70  -  568988479.088177 [ -0.98607182  -7.16103704 -16.55738265]\n",
      "Output at run 80  -  512446051.58835006 [ -1.03754332  -7.15625821 -17.7477061 ]\n",
      "Output at run 90  -  467915861.76079655 [ -1.07831333  -7.04596065 -18.79818365]\n",
      "Output at run 100  -  431450841.75270486 [ -1.11060215  -6.85522077 -19.73469998]\n",
      "Output at run 110  -  400543306.85067093 [ -1.13616878  -6.60381066 -20.57785445]\n",
      "Output at run 120  -  373590652.44631225 [ -1.15640676  -6.30730317 -21.34405668]\n",
      "Output at run 130  -  349559944.90087444 [ -1.17242014  -5.97794728 -22.04639453]\n",
      "Output at run 140  -  327777335.53735733 [ -1.18508365  -5.62536139 -22.69532184]\n",
      "Output at run 150  -  307795813.8467466 [ -1.1950903   -5.25708255 -23.29920327]\n",
      "Output at run 160  -  289312128.31510675 [ -1.20298919  -4.87900141 -23.86474598]\n",
      "Output at run 170  -  272114567.7488589 [ -1.20921541  -4.49570673 -24.39734173]\n",
      "Output at run 180  -  256050114.0580119 [ -1.21411369  -4.11075826 -24.9013379 ]\n",
      "Output at run 190  -  241003756.20313546 [ -1.21795724  -3.7269028  -25.38025228]\n",
      "Output at run 200  -  226885440.18098015 [ -1.22096255  -3.34624528 -25.83694331]\n",
      "Output at run 210  -  213621815.03298163 [ -1.22330121  -2.97038429 -26.27374496]\n",
      "Output at run 220  -  201150992.3757708 [ -1.22510923  -2.60051932 -26.69257366]\n",
      "Output at run 230  -  189419200.61617872 [ -1.22649442  -2.23753567 -27.09501313]\n",
      "Output at run 240  -  178378631.51189414 [ -1.22754227  -1.88207168 -27.48238151]\n",
      "Output at run 250  -  167986038.12715924 [ -1.22832056  -1.53457191 -27.85578473]\n",
      "Output at run 260  -  158201807.2799362 [ -1.22888308  -1.19532919 -28.21615877]\n",
      "Output at run 270  -  148989332.5363032 [ -1.22927248  -0.86451796 -28.5643032 ]\n",
      "Output at run 280  -  140314578.4305942 [ -1.22952262  -0.54222051 -28.90090782]\n",
      "Output at run 290  -  132145767.15361063 [ -1.2296604   -0.22844784 -29.2265738 ]\n",
      "Output at run 300  -  124453144.41617228 [ -1.22970718   0.07684397 -29.54183049]\n",
      "Output at run 310  -  117208797.18430278 [ -1.22967993   0.37374076 -29.84714876]\n",
      "Output at run 320  -  110386506.02422523 [ -1.22959218   0.66236009 -30.14295166]\n",
      "Output at run 330  -  103961621.1045908 [ -1.22945467   0.94284317 -30.42962284]\n",
      "Output at run 340  -  97910954.86975087 [ -1.22927598   1.21534852 -30.70751333]\n",
      "Output at run 350  -  92212686.89358191 [ -1.22906296   1.48004701 -30.97694693]\n",
      "Output at run 360  -  86846277.99575107 [ -1.22882108   1.73711795 -31.23822448]\n",
      "Output at run 370  -  81792391.69489673 [ -1.22855474   1.98674603 -31.49162739]\n",
      "Output at run 380  -  77032821.70158698 [ -1.22826746   2.22911895 -31.73742033]\n",
      "Output at run 390  -  72550424.55343895 [ -1.22796206   2.46442557 -31.97585352]\n",
      "Output at run 400  -  68329056.75037023 [ -1.22764085   2.69285446 -32.20716452]\n",
      "Output at run 410  -  64353515.91293521 [ -1.22730569   2.91459286 -32.43157972]\n",
      "Output at run 420  -  60609485.59454748 [ -1.22695809   3.12982577 -32.64931549]\n",
      "Output at run 430  -  57083483.45014406 [ -1.2265993    3.3387354  -32.86057921]\n",
      "Output at run 440  -  53762812.51269695 [ -1.22623034   3.54150065 -33.06557004]\n",
      "Output at run 450  -  50635515.363249384 [ -1.22585206   3.73829678 -33.26447963]\n",
      "Output at run 460  -  47690331.005048044 [ -1.22546517   3.9292952  -33.45749265]\n",
      "Output at run 470  -  44916654.27117223 [ -1.22507028   4.11466329 -33.64478731]\n",
      "Output at run 480  -  42304497.60988425 [ -1.22466789   4.2945643  -33.8265357 ]\n",
      "Output at run 490  -  39844455.10406585 [ -1.22425844   4.46915732 -34.0029042 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -1.22388422,   4.62188081, -34.15716917])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lr(y,x,.0001,500,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:39.257451Z",
     "start_time": "2023-06-04T09:20:39.252459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5101277623905958, 9.999609579613075, -40.00052619962942]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see that if we take too few steps , we did not reach to the optimal value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets increase the learning rate $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:20:40.018721Z",
     "start_time": "2023-06-04T09:20:39.258448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at run 0  -  4088458322.8865066 [ -2.88160857 -27.5117754  -42.00705457]\n",
      "Output at run 10  -  735760564829.148 [ -25.67130698 -273.72566791 -320.05683848]\n",
      "Output at run 20  -  145722946650892.38 [ -346.90755478 -3978.53510841 -3991.04783914]\n",
      "Output at run 30  -  2.8861546187014172e+16 [ -4868.5308406  -56124.20015087 -55647.0744807 ]\n",
      "Output at run 40  -  5.716250376246971e+18 [ -68503.44220739 -789985.74432091 -782617.40231898]\n",
      "Output at run 50  -  1.1321471882440665e+21 [  -964057.14934867 -11117836.51056523 -11013486.0291238 ]\n",
      "Output at run 60  -  2.242304258006449e+23 [-1.35674504e+07 -1.56464738e+08 -1.54995529e+08]\n",
      "Output at run 70  -  4.441055401349398e+25 [-1.90938736e+08 -2.20197472e+09 -2.18129746e+09]\n",
      "Output at run 80  -  8.795850521815283e+27 [-2.68713735e+09 -3.09890423e+10 -3.06980444e+10]\n",
      "Output at run 90  -  1.742085594757739e+30 [-3.78168795e+10 -4.36117968e+11 -4.32022668e+11]\n",
      "Output at run 100  -  3.4503340091278715e+32 [-5.32208142e+11 -6.13761729e+12 -6.07998291e+12]\n",
      "Output at run 110  -  6.833650889696863e+34 [-7.48992276e+12 -8.63765054e+13 -8.55653997e+13]\n",
      "Output at run 120  -  1.3534569221041486e+37 [-1.05407901e+14 -1.21560213e+15 -1.20418720e+15]\n",
      "Output at run 130  -  2.680625143952754e+39 [-1.48343660e+15 -1.71075288e+16 -1.69468831e+16]\n",
      "Output at run 140  -  5.3091835026565715e+41 [-2.08768424e+16 -2.40759317e+17 -2.38498503e+17]\n",
      "Output at run 150  -  1.0515244747468288e+44 [-2.93805985e+17 -3.38827716e+18 -3.35646005e+18]\n",
      "Output at run 160  -  2.08262479614488e+46 [-4.13481861e+18 -4.76842276e+19 -4.72364560e+19]\n",
      "Output at run 170  -  4.124797991565342e+48 [-5.81905266e+19 -6.71074254e+20 -6.64772632e+20]\n",
      "Output at run 180  -  8.169478488259564e+50 [-8.18932510e+20 -9.44422667e+21 -9.35554207e+21]\n",
      "Output at run 190  -  1.6180278138859384e+53 [-1.15250797e+22 -1.32911398e+23 -1.31663314e+23]\n",
      "Output at run 200  -  3.2046280680840225e+55 [-1.62195859e+23 -1.87050146e+24 -1.85293679e+24]\n",
      "Output at run 210  -  6.347011446044124e+57 [-2.28263034e+24 -2.63241209e+25 -2.60769281e+25]\n",
      "Output at run 220  -  1.257074251374843e+60 [-3.21241327e+25 -3.70467147e+26 -3.66988330e+26]\n",
      "Output at run 230  -  2.4897318791736536e+62 [-4.52092430e+26 -5.21369385e+27 -5.16473543e+27]\n",
      "Output at run 240  -  4.9311047644115746e+64 [-6.36243063e+27 -7.33738572e+28 -7.26848509e+28]\n",
      "Output at run 250  -  9.766430835786625e+66 [-8.95403700e+28 -1.03261202e+30 -1.02291543e+30]\n",
      "Output at run 260  -  1.934316463089506e+69 [-1.26012814e+30 -1.45322546e+31 -1.43957917e+31]\n",
      "Output at run 270  -  3.8310619737038496e+71 [-1.77341564e+31 -2.04516722e+32 -2.02596239e+32]\n",
      "Output at run 280  -  7.587711797126225e+73 [-2.49578034e+32 -2.87822439e+33 -2.85119685e+33]\n",
      "Output at run 290  -  1.5028044628728994e+76 [-3.51238556e+33 -4.05061040e+34 -4.01257375e+34]\n",
      "Output at run 300  -  2.976419392320706e+78 [-4.94308420e+34 -5.70054394e+35 -5.64701384e+35]\n",
      "Output at run 310  -  5.895026677021535e+80 [-6.95654874e+35 -8.02254428e+36 -7.94720977e+36]\n",
      "Output at run 320  -  1.1675552045002566e+83 [-9.79015702e+36 -1.12903641e+38 -1.11843436e+38]\n",
      "Output at run 330  -  2.312432547369548e+85 [-1.37779778e+38 -1.58892637e+39 -1.57400579e+39]\n",
      "Output at run 340  -  4.579949852069602e+87 [-1.93901562e+39 -2.23614312e+40 -2.21514495e+40]\n",
      "Output at run 350  -  9.070941624365665e+89 [-2.72883409e+40 -3.14699042e+41 -3.11743908e+41]\n",
      "Output at run 360  -  1.7965694955255339e+92 [-3.84036900e+41 -4.42885280e+42 -4.38726432e+42]\n",
      "Output at run 370  -  3.558243549471184e+94 [-5.40466501e+42 -6.23285567e+43 -6.17432697e+43]\n",
      "Output at run 380  -  7.047374003002089e+96 [-7.60614508e+43 -8.77168233e+44 -8.68931316e+44]\n",
      "Output at run 390  -  1.3957864223648029e+99 [-1.07043532e+45 -1.23446483e+46 -1.22287277e+46]\n",
      "Output at run 400  -  2.7644619627509755e+101 [-1.50645532e+46 -1.73729890e+47 -1.72098505e+47]\n",
      "Output at run 410  -  5.475228746350136e+103 [-2.12007917e+47 -2.44495218e+48 -2.42199322e+48]\n",
      "Output at run 420  -  1.084411007595386e+106 [-2.98365019e+48 -3.44085359e+49 -3.40854277e+49]\n",
      "Output at run 430  -  2.1477590944084935e+108 [-4.19897925e+49 -4.84241514e+50 -4.79694316e+50]\n",
      "Output at run 440  -  4.2538014602444395e+110 [-5.90934782e+50 -6.81487420e+51 -6.75088014e+51]\n",
      "Output at run 450  -  8.42497974297308e+112 [-8.31640015e+51 -9.59077423e+52 -9.50071350e+52]\n",
      "Output at run 460  -  1.6686317951808713e+115 [-1.17039162e+53 -1.34973805e+54 -1.33706354e+54]\n",
      "Output at run 470  -  3.304853130609384e+117 [-1.64712678e+54 -1.89952633e+55 -1.88168911e+55]\n",
      "Output at run 480  -  6.545514862201664e+119 [-2.31805028e+55 -2.67325964e+56 -2.64815680e+56]\n",
      "Output at run 490  -  1.2963893739932322e+122 [-3.26226079e+56 -3.76215744e+57 -3.72682947e+57]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.52431663e+57, 4.06436973e+58, 4.02620388e+58])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lr(y,x,.01,500,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that because of high learning rate , change is parameter is huge and we end up missing the optimal point , cost function values , as well as parameter values ended up exploding. Now lets run with low learning rate and higher number of steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:22:31.399895Z",
     "start_time": "2023-06-04T09:20:40.020717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at run 0  -  2457990424.9895744 [ 0.701662   -0.70233504 -1.39203517]\n",
      "Output at run 1000  -  39777.90011758702 [ -0.31327393  10.16459105 -39.83239211]\n",
      "Output at run 2000  -  36014.60943594408 [ -0.11966909  10.15637288 -39.84104314]\n",
      "Output at run 3000  -  32622.814027076223 [  0.06413236  10.14843488 -39.84911886]\n",
      "Output at run 4000  -  29565.82138090001 [  0.2386267   10.14089884 -39.85678565]\n",
      "Output at run 5000  -  26810.583251164753 [  0.40428519  10.1337444  -39.86406421]\n",
      "Output at run 6000  -  24327.313570734026 [  0.56155525  10.12695223 -39.87097422]\n",
      "Output at run 7000  -  22089.1664431983 [  0.71086166  10.120504   -39.87753432]\n",
      "Output at run 8000  -  20071.945919799637 [  0.85260766  10.11438229 -39.88376224]\n",
      "Output at run 9000  -  18253.844424166506 [  0.98717609  10.10857056 -39.8896748 ]\n",
      "Output at run 10000  -  16615.206997032506 [  1.1149304   10.10305312 -39.89528797]\n",
      "Output at run 11000  -  15138.318812267535 [  1.23621564  10.09781507 -39.9006169 ]\n",
      "Output at run 12000  -  13807.213667114513 [  1.35135937  10.09284225 -39.90567599]\n",
      "Output at run 13000  -  12607.501376278567 [  1.46067259  10.08812124 -39.9104789 ]\n",
      "Output at run 14000  -  11526.212203876417 [  1.56445053  10.08363929 -39.91503862]\n",
      "Output at run 15000  -  10551.656651445108 [  1.66297349  10.07938429 -39.91936744]\n",
      "Output at run 16000  -  9673.299086220695 [  1.75650755  10.07534475 -39.92347706]\n",
      "Output at run 17000  -  8881.643843518545 [  1.84530534  10.07150976 -39.92737859]\n",
      "Output at run 18000  -  8168.132571901073 [  1.9296067   10.06786896 -39.93108255]\n",
      "Output at run 19000  -  7525.0517113646765 [  2.0096393   10.06441252 -39.93459896]\n",
      "Output at run 20000  -  6945.449104315752 [  2.0856193   10.06113111 -39.9379373 ]\n",
      "Output at run 21000  -  6423.058837844912 [  2.15775191  10.05801585 -39.94110661]\n",
      "Output at run 22000  -  5952.233504790009 [  2.22623196  10.05505834 -39.94411543]\n",
      "Output at run 23000  -  5527.883151281106 [  2.29124439  10.05225059 -39.94697189]\n",
      "Output at run 24000  -  5145.420250751476 [  2.3529648   10.04958502 -39.94968371]\n",
      "Output at run 25000  -  4800.710109539161 [  2.41155988  10.04705442 -39.95225822]\n",
      "Output at run 26000  -  4490.0261679331625 [  2.46718789  10.04465196 -39.95470236]\n",
      "Output at run 27000  -  4210.009713434865 [  2.51999907  10.04237116 -39.95702273]\n",
      "Output at run 28000  -  3957.6335707077983 [  2.57013606  10.04020585 -39.95922561]\n",
      "Output at run 29000  -  3730.16937567721 [  2.61773428  10.03815018 -39.96131694]\n",
      "Output at run 30000  -  3525.1580799902513 [  2.66292227  10.03619861 -39.96330237]\n",
      "Output at run 31000  -  3340.3833669697005 [  2.70582208  10.03434585 -39.96518727]\n",
      "Output at run 32000  -  3173.8476916674044 [  2.74654958  10.03258692 -39.96697672]\n",
      "Output at run 33000  -  3023.750685994706 [  2.78521477  10.03091705 -39.96867556]\n",
      "Output at run 34000  -  2888.469695474389 [  2.82192208  10.02933174 -39.97028838]\n",
      "Output at run 35000  -  2766.5422372005196 [  2.85677064  10.0278267  -39.97181953]\n",
      "Output at run 36000  -  2656.650189367736 [  2.88985458  10.02639788 -39.97327314]\n",
      "Output at run 37000  -  2557.6055414448447 [  2.92126326  10.0250414  -39.97465315]\n",
      "Output at run 38000  -  2468.33755094294 [  2.9510815   10.02375361 -39.97596328]\n",
      "Output at run 39000  -  2387.8811679341734 [  2.97938984  10.02253104 -39.97720707]\n",
      "Output at run 40000  -  2315.366602181558 [  3.00626473  10.02137037 -39.97838788]\n",
      "Output at run 41000  -  2250.0099200931027 [  3.03177877  10.02026847 -39.97950889]\n",
      "Output at run 42000  -  2191.1045698469716 [  3.05600085  10.01922237 -39.98057314]\n",
      "Output at run 43000  -  2138.0137430676277 [  3.0789964   10.01822924 -39.9815835 ]\n",
      "Output at run 44000  -  2090.163490478884 [  3.10082753  10.0172864  -39.9825427 ]\n",
      "Output at run 45000  -  2047.0365171068643 [  3.12155321  10.0163913  -39.98345333]\n",
      "Output at run 46000  -  2008.166589956994 [  3.1412294   10.01554153 -39.98431784]\n",
      "Output at run 47000  -  1973.1334977062083 [  3.15990924  10.01473478 -39.98513858]\n",
      "Output at run 48000  -  1941.55850792249 [  3.17764321  10.01396889 -39.98591776]\n",
      "Output at run 49000  -  1913.1002727001057 [  3.19447917  10.01324178 -39.98665749]\n",
      "Output at run 50000  -  1887.4511384479028 [  3.21046262  10.01255149 -39.98735976]\n",
      "Output at run 51000  -  1864.3338199372547 [  3.22563672  10.01189615 -39.98802646]\n",
      "Output at run 52000  -  1843.4984026530394 [  3.24004245  10.011274   -39.98865941]\n",
      "Output at run 53000  -  1824.71964104167 [  3.25371872  10.01068335 -39.98926031]\n",
      "Output at run 54000  -  1807.7945234475171 [  3.26670246  10.01012261 -39.98983078]\n",
      "Output at run 55000  -  1792.540077414111 [  3.27902875  10.00959026 -39.99037236]\n",
      "Output at run 56000  -  1778.7913916225943 [  3.29073087  10.00908487 -39.99088652]\n",
      "Output at run 57000  -  1766.3998330842196 [  3.30184044  10.00860507 -39.99137464]\n",
      "Output at run 58000  -  1755.2314403127925 [  3.31238745  10.00814957 -39.99183805]\n",
      "Output at run 59000  -  1745.1654751067072 [  3.3224004   10.00771713 -39.99227799]\n",
      "Output at run 60000  -  1736.0931172836908 [  3.33190632  10.00730659 -39.99269565]\n",
      "Output at run 61000  -  1727.9162882580133 [  3.34093089  10.00691684 -39.99309217]\n",
      "Output at run 62000  -  1720.5465907417156 [  3.34949849  10.00654682 -39.9934686 ]\n",
      "Output at run 63000  -  1713.904353107643 [  3.35763225  10.00619554 -39.99382598]\n",
      "Output at run 64000  -  1707.9177680829473 [  3.36535414  10.00586205 -39.99416525]\n",
      "Output at run 65000  -  1702.5221164618792 [  3.37268502  10.00554544 -39.99448735]\n",
      "Output at run 66000  -  1697.6590674454717 [  3.37964468  10.00524487 -39.99479314]\n",
      "Output at run 67000  -  1693.276048044528 [  3.38625194  10.00495952 -39.99508344]\n",
      "Output at run 68000  -  1689.325674728463 [  3.39252462  10.00468861 -39.99535905]\n",
      "Output at run 69000  -  1685.7652411759834 [  3.39847967  10.00443143 -39.9956207 ]\n",
      "Output at run 70000  -  1682.5562565896294 [  3.40413318  10.00418726 -39.9958691 ]\n",
      "Output at run 71000  -  1679.6640295830975 [  3.40950041  10.00395546 -39.99610492]\n",
      "Output at run 72000  -  1677.0572931428787 [  3.41459586  10.0037354  -39.9963288 ]\n",
      "Output at run 73000  -  1674.707866609834 [  3.41943329  10.00352648 -39.99654134]\n",
      "Output at run 74000  -  1672.5903510263527 [  3.42402577  10.00332814 -39.99674312]\n",
      "Output at run 75000  -  1670.6818545557499 [  3.42838571  10.00313985 -39.99693468]\n",
      "Output at run 76000  -  1668.961745005312 [  3.43252487  10.00296109 -39.99711655]\n",
      "Output at run 77000  -  1667.4114267778243 [  3.43645443  10.00279138 -39.9972892 ]\n",
      "Output at run 78000  -  1666.0141398399705 [  3.44018502  10.00263026 -39.99745311]\n",
      "Output at run 79000  -  1664.7547785346133 [  3.4437267   10.0024773  -39.99760872]\n",
      "Output at run 80000  -  1663.6197282779553 [  3.44708904  10.00233209 -39.99775646]\n",
      "Output at run 81000  -  1662.5967183763335 [  3.45028112  10.00219423 -39.99789671]\n",
      "Output at run 82000  -  1661.6746893712348 [  3.45331157  10.00206335 -39.99802986]\n",
      "Output at run 83000  -  1660.8436734789534 [  3.45618856  10.0019391  -39.99815626]\n",
      "Output at run 84000  -  1660.094686831684 [  3.45891987  10.00182114 -39.99827627]\n",
      "Output at run 85000  -  1659.4196323555716 [  3.46151288  10.00170915 -39.9983902 ]\n",
      "Output at run 86000  -  1658.8112122356958 [  3.46397458  10.00160284 -39.99849836]\n",
      "Output at run 87000  -  1658.2628490215302 [  3.46631163  10.00150191 -39.99860104]\n",
      "Output at run 88000  -  1657.7686145200073 [  3.46853034  10.00140608 -39.99869853]\n",
      "Output at run 89000  -  1657.3231657076478 [  3.4706367   10.00131512 -39.99879107]\n",
      "Output at run 90000  -  1656.921686968676 [  3.47263641  10.00122875 -39.99887893]\n",
      "Output at run 91000  -  1656.559838034788 [  3.47453485  10.00114676 -39.99896235]\n",
      "Output at run 92000  -  1656.2337070638528 [  3.47633716  10.00106892 -39.99904154]\n",
      "Output at run 93000  -  1655.9397683500863 [  3.47804821  10.00099503 -39.99911671]\n",
      "Output at run 94000  -  1655.6748442087162 [  3.47967262  10.00092487 -39.99918809]\n",
      "Output at run 95000  -  1655.4360706229456 [  3.48121477  10.00085827 -39.99925584]\n",
      "Output at run 96000  -  1655.2208662819376 [  3.48267883  10.00079504 -39.99932017]\n",
      "Output at run 97000  -  1655.0269046750082 [  3.48406876  10.00073501 -39.99938124]\n",
      "Output at run 98000  -  1654.8520889403983 [  3.48538831  10.00067802 -39.99943922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at run 99000  -  1654.6945291967518 [  3.48664104  10.00062392 -39.99949426]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  3.48782917,  10.00057261, -39.99954646])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lr(y,x,.0004,100000,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we ended up getting pretty good estimates for $\\beta$s , as good as from sklearn ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T09:22:31.406373Z",
     "start_time": "2023-06-04T09:22:31.400906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5101277623905958, 9.999609579613075, -40.00052619962942]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " there are modifications to gradient descent which can achieve the same thing in much less number of iterations. We'll discuss that in detail when we start with our course in Deep learning. For now ,we'll conclude this module "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
